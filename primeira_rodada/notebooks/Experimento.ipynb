{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji, re, string, time, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "#dataviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#data balancing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "sns.set(style=\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ee5f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/viral-15-words/ml/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = 'viral-15-words'\n",
    "path_dir = 'results/' + subset + '/ml/'\n",
    "path_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84393ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "dataframe_golpe_telegram.csv\n",
      "dataframe_rotulado_completo.csv\n",
      "dataset_sem_repeticoes.csv\n",
      "dataset_telegram_processado.csv\n",
      "grouped_texts.pickle\n",
      "preprocessed_corpus.p.pickle\n",
      "processed_texts.p\n",
      "telegram_content_only.csv\n",
      "telegram_experimentos.csv\n",
      "train-test\n",
      "word2vec.model\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data' #+ '/vis_processed_texts.p'\n",
    "preprocessed = False # the texts were already pre-processed\n",
    "processed_texts_filename = 'processed_texts-'+subset+'.p'\n",
    "for filename in os.listdir(data_dir):\n",
    "    print(filename)\n",
    "    if filename == processed_texts_filename:\n",
    "        preprocessed = True\n",
    "preprocessed \n",
    "\n",
    "filepath = '../data/telegram_experimentos.csv'\n",
    "df = pd.read_csv(filepath)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1abba4",
   "metadata": {},
   "source": [
    "# Funções que serão usadas para processamento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06ad9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_emoji = {}\n",
    "for key, value in emoji.EMOJI_DATA.items():\n",
    "    try:\n",
    "        unicode_emoji[key] = value['pt']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#emojis and punctuation\n",
    "emojis_list = list(unicode_emoji)\n",
    "punct = list(string.punctuation)\n",
    "emojis_punct = emojis_list + punct\n",
    "\n",
    "def processEmojisPunctuation(text, remove_punct = True):\n",
    "    '''\n",
    "    Put spaces between emojis. Removes punctuation.\n",
    "    '''\n",
    "    #get all unique chars\n",
    "    chars = set(text)\n",
    "    #for each unique char in text, do:\n",
    "    for c in chars:\n",
    "        #remove punctuation\n",
    "        if remove_punct:\n",
    "            if c in emojis_list:\n",
    "                text = text.replace(c, ' ' + c + ' ')\n",
    "            if c in punct:\n",
    "                text = text.replace(c, ' ')\n",
    "\n",
    "        #put spaces between punctuation\n",
    "        else:\n",
    "            if c in emojis_punct:\n",
    "                text = text.replace(c, ' ' + c + ' ')          \n",
    "\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "#stop words removal\n",
    "stop_words = list(stopwords.words('portuguese'))\n",
    "new_stopwords = ['aí','pra','vão','vou','onde','lá','aqui',\n",
    "                 'tá','pode','pois','so','deu','agora','todo',\n",
    "                 'nao','ja','vc', 'bom', 'ai','kkk','kkkk','ta', 'voce', 'alguem', 'ne', 'pq',\n",
    "                 'cara','to','mim','la','vcs','tbm', 'tudo']\n",
    "stop_words = stop_words + new_stopwords\n",
    "final_stop_words = []\n",
    "for sw in stop_words:\n",
    "    sw = ' '+ sw + ' '\n",
    "    final_stop_words.append(sw)\n",
    "\n",
    "def removeStopwords(text):\n",
    "    for sw in final_stop_words:\n",
    "        text = text.replace(sw,' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    return text\n",
    "\n",
    "#lemmatization\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.text != token.lemma_:\n",
    "            text = text.replace(token.text, token.lemma_)\n",
    "    return text\n",
    "\n",
    "\n",
    "def domainUrl(text):\n",
    "    '''\n",
    "    Substitutes an URL in a text for the domain of this URL\n",
    "    Input: an string\n",
    "    Output: the string with the modified URL\n",
    "    '''    \n",
    "    if 'http' in text:\n",
    "        re_url = '[^\\s]*https*://[^\\s]*'\n",
    "        matches = re.findall(re_url, text, flags=re.IGNORECASE)\n",
    "        for m in matches:\n",
    "            domain = m.split('//')\n",
    "            domain = domain[1].split('/')[0]\n",
    "            text = re.sub(re_url, domain, text, 1)\n",
    "        return text\n",
    "    else:\n",
    "        return text \n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = domainUrl(text)\n",
    "    text = processEmojisPunctuation(text)\n",
    "    text = removeStopwords(text)\n",
    "    text = lemmatization(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b33d19",
   "metadata": {},
   "source": [
    "# Definir quais experimentos serão feitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76407ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['ml-tfidf-unibitri_gram-random_oversampling',\n",
    " 'ml-tfidf-unibi_gram-random_oversampling',\n",
    " 'ml-tfidf-unibitri_gram-processed-random_oversampling',\n",
    " 'ml-tfidf-unibitriquad_gram-processed-random_oversampling',\n",
    " 'ml-tfidf-bigram-random_oversampling',\n",
    " 'ml-bow-unibitri_gram-random_oversampling',\n",
    " 'ml-tfidf-processed-smote',\n",
    " 'ml-bow-processed-random_oversampling',\n",
    " 'ml-tfidf-random_oversampling',\n",
    " 'ml-tfidf-processed-random_oversampling',\n",
    " 'ml-tfidf-smote',\n",
    " 'ml-tfidf-undersampling',\n",
    " 'ml-tfidf',\n",
    " 'ml-tfidf-processed',\n",
    " 'ml-bow-unibitri_gram-processed-random_oversampling',\n",
    " 'ml-bow-random_oversampling',\n",
    " 'ml-bow',\n",
    " 'ml-bow-processed',\n",
    " 'ml-bow-random_oversampling-processed',\n",
    " 'ml-bow-random_oversampling-max_features',\n",
    " 'ml-tfidf-random_oversampling-max_features',\n",
    " 'ml-tfidf-processed-random_oversampling-max_features',\n",
    " 'ml-bow-processed-random_oversampling-max_features',\n",
    " 'ml-tfidf-trigram-random_oversampling',\n",
    " 'ml-bow-processed-smote']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bdc1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments1 = ['ml-tfidf-unibi_gram-processed-random_oversampling',\n",
    "               'ml-bow-unibi_gram-processed-random_oversampling',\n",
    "               'ml-bow-unibi_gram-random_oversampling'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f36bf",
   "metadata": {},
   "source": [
    "# Definindo a função getTestMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b979eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def getTestMetrics(y_test, y_pred, y_prob,full_metrics=True, print_charts=False):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    precision_neg = precision_score(y_test, y_pred, pos_label=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    recall_neg = recall_score(y_test, y_pred, pos_label=0)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    return (acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df04daf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 653\n",
      "Olá TfidfVectorizer(ngram_range=(1, 2))\n",
      "Logistic Regression\n",
      "Bernoulli Naive-Bayes\n",
      "Multinomial Naive-Bayes\n",
      "Linear Support Vector Machine\n",
      "KNN\n",
      "Linear SVM with SGD training.\n",
      "Random Forest\n",
      "Gradient Boosting\n",
      "Multilayer perceptron\n",
      "Iteration 1, loss = 0.58602275\n",
      "Validation score: 0.993421\n",
      "Iteration 2, loss = 0.31341921\n",
      "Validation score: 0.993421\n",
      "Iteration 3, loss = 0.15182036\n",
      "Validation score: 0.995614\n",
      "Iteration 4, loss = 0.07940967\n",
      "Validation score: 0.995614\n",
      "Iteration 5, loss = 0.04756176\n",
      "Validation score: 0.995614\n",
      "Iteration 6, loss = 0.03172811\n",
      "Validation score: 0.995614\n",
      "ellapsed time (min): 3.434911223252614\n",
      "../results/ml-tfidf-unibi_gram-processed-random_oversampling.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá CountVectorizer(binary=True, ngram_range=(1, 2))\n",
      "Logistic Regression\n",
      "Bernoulli Naive-Bayes\n",
      "Multinomial Naive-Bayes\n",
      "Linear Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Linear SVM with SGD training.\n",
      "Random Forest\n",
      "Gradient Boosting\n",
      "Multilayer perceptron\n",
      "Iteration 1, loss = 0.29265859\n",
      "Validation score: 0.995614\n",
      "Iteration 2, loss = 0.03648675\n",
      "Validation score: 0.997807\n",
      "Iteration 3, loss = 0.01432455\n",
      "Validation score: 0.997807\n",
      "Iteration 4, loss = 0.00907153\n",
      "Validation score: 0.997807\n",
      "Iteration 5, loss = 0.00659063\n",
      "Validation score: 0.997807\n",
      "Iteration 6, loss = 0.00522914\n",
      "Validation score: 0.997807\n",
      "ellapsed time (min): 3.1309083461761475\n",
      "../results/ml-bow-unibi_gram-processed-random_oversampling.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá CountVectorizer(binary=True, ngram_range=(1, 2))\n",
      "Logistic Regression\n",
      "Bernoulli Naive-Bayes\n",
      "Multinomial Naive-Bayes\n",
      "Linear Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Linear SVM with SGD training.\n",
      "Random Forest\n",
      "Gradient Boosting\n",
      "Multilayer perceptron\n",
      "Iteration 1, loss = 0.24709085\n",
      "Validation score: 0.993421\n",
      "Iteration 2, loss = 0.02369632\n",
      "Validation score: 0.995614\n",
      "Iteration 3, loss = 0.00876925\n",
      "Validation score: 0.995614\n",
      "Iteration 4, loss = 0.00592191\n",
      "Validation score: 0.995614\n",
      "Iteration 5, loss = 0.00455981\n",
      "Validation score: 0.995614\n",
      "Iteration 6, loss = 0.00373556\n",
      "Validation score: 0.997807\n",
      "ellapsed time (min): 2.81797620455424\n",
      "../results/ml-bow-unibi_gram-random_oversampling.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for experiment in experiments1:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if subset == 'viral':\n",
    "        df = df[df['viral']==1]\n",
    "        \n",
    "    if subset == 'viral-15-words':\n",
    "        df = df[df['sharings']>1]\n",
    "        df = df[df['words']>15]\n",
    "    \n",
    "    \n",
    "    texts = df['text_content']\n",
    "    y = df['Golpe']\n",
    "       \n",
    "    #removing duplicates\n",
    "        \n",
    "    df = df.drop_duplicates(subset=['text_content'])    \n",
    "    texts = df['text_content']\n",
    "    y = df['Golpe']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # # Pre-processing\n",
    "    # * convert url in just the domain\n",
    "    # * separate emojis\n",
    "    # * punctuation\n",
    "    \n",
    "    # [Some suggestions in this work](https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/03.%20Feature%20Engineering/03.%20Feature%20Engineering.ipynb)\n",
    "    # \n",
    "    # * **Special character cleaning**\n",
    "    # \n",
    "    # * **Upcase/downcase**\n",
    "    # \n",
    "    # * **Punctuation signs** \n",
    "    # \n",
    "    # * **Possessive pronouns**\n",
    "    # \n",
    "    # * **Stemming or Lemmatization**\n",
    "    # \n",
    "    # * **Stop words**  \n",
    "    \n",
    "    #if experiment is with pre-processed text\n",
    "    if 'processed' in experiment:\n",
    "            #text was already pre-processed\n",
    "            if preprocessed:\n",
    "                if subset != 'viral':\n",
    "                    pro_texts = pickle.load(open( \"../data/processed_texts.p\", \"rb\" ))\n",
    "                else:\n",
    "                    pro_texts = pickle.load(open( \"../data/processed_texts-viral.p\", \"rb\" ))\n",
    "            else:\n",
    "                pro_texts = [preprocess(t) for t in texts]\n",
    "                if subset != 'viral':\n",
    "                    pickle.dump(pro_texts, open( \"../data/processed_texts.p\", \"wb\" ))\n",
    "                else:\n",
    "                    pickle.dump(pro_texts, open( \"../data/processed_texts-viral.p\", \"wb\" ))\n",
    "    else:\n",
    "        #only use lowercase and separates emojis and punctuation\n",
    "        pro_texts = [processEmojisPunctuation(t.lower(),remove_punct = False) for t in texts]\n",
    "    \n",
    "    # Train-test split\n",
    "    \n",
    "    #random state = 42 for reprudictibility\n",
    "    texts_train, texts_test, y_train, y_test = train_test_split(pro_texts, y, test_size=0.2, \n",
    "                                                                        stratify = y, random_state=42)\n",
    "    \n",
    "    full_texts_train, full_texts_test, y_train, y_test = train_test_split(texts, y, test_size=0.2, \n",
    "                                                                        stratify = y, random_state=42)\n",
    "    \n",
    "    # Vectorization\n",
    "    \n",
    "    max_feat = 500\n",
    "    #print(experiment)\n",
    "    #vectorizer = None\n",
    "    \n",
    "    if 'tfidf' in experiment:\n",
    "        if 'max_features' in experiment:\n",
    "            vectorizer = TfidfVectorizer(max_features = max_feat)\n",
    "        elif 'bigram' in experiment:\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(2,2))\n",
    "        elif 'trigram' in experiment:\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(3,3)) \n",
    "        elif 'unibi_gram' in experiment:\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(1,2))\n",
    "        elif 'unibitri_gram' in experiment:\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(1,3))       \n",
    "        elif 'unibitriquad_gram' in experiment:\n",
    "            vectorizer = TfidfVectorizer(ngram_range =(1,3))  \n",
    "        else:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            \n",
    "    elif 'bow' in experiment:\n",
    "        if 'max_features' in experiment:\n",
    "            vectorizer = CountVectorizer(max_features = max_feat, binary=True)\n",
    "        elif 'bigram' in experiment:\n",
    "            vectorizer = CountVectorizer(binary=True, ngram_range =(2,2))\n",
    "        elif 'trigram' in experiment:\n",
    "            vectorizer = CountVectorizer(binary=True, ngram_range =(3,3)) \n",
    "        elif 'unibi_gram' in experiment:\n",
    "            vectorizer = CountVectorizer(binary=True, ngram_range =(1,2))\n",
    "        elif 'unibitri_gram' in experiment:\n",
    "            vectorizer = CountVectorizer(binary=True, ngram_range =(1,3))\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(binary=True)\n",
    "    print(\"Olá\", vectorizer)\n",
    "    vectorizer.fit(texts_train)   \n",
    "    X_train = vectorizer.transform(texts_train)\n",
    "    X_test = vectorizer.transform(texts_test)\n",
    "    X = vectorizer.transform(pro_texts)\n",
    "    \n",
    "    \n",
    "    if 'smote' in experiment:\n",
    "        #oversampling with SMOTE\n",
    "        sm = SMOTE(random_state = 42)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    elif 'undersampling' in experiment:\n",
    "        rus = RandomUnderSampler(random_state = 42)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "    elif 'random_oversampling' in experiment:\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    vocab_size = X_train.shape[1]\n",
    "    \n",
    "    # Metrics\n",
    "    scenario = []\n",
    "    model = []\n",
    "    accuracy_score_list = []\n",
    "    precision_score_list = []\n",
    "    precision_score_neg_list = []\n",
    "    recall_score_list = []\n",
    "    recall_score_neg_list = []\n",
    "    f1_score_list = []\n",
    "    f1_score_neg_list = []\n",
    "    auc_score_list = []\n",
    "       \n",
    "    # ## Models training and test\n",
    "    \n",
    "    # ## Models training and test\n",
    "    \n",
    "    # In[39]:\n",
    "    \n",
    "    \n",
    "    print('Logistic Regression')\n",
    "    logreg = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    y_prob = logreg.predict_proba(X_test)[:,1]\n",
    "    model.append('logistic regression')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[25]:\n",
    "    \n",
    "    \n",
    "    print('Bernoulli Naive-Bayes')\n",
    "    bnb = BernoulliNB().fit(X_train, y_train)\n",
    "    y_pred = bnb.predict(X_test)\n",
    "    y_prob = bnb.predict_proba(X_test)[:,1]\n",
    "    model.append('bernoulli naive-bayes')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[40]:\n",
    "    \n",
    "    \n",
    "    print('Multinomial Naive-Bayes')\n",
    "    mnb = MultinomialNB().fit(X_train, y_train)\n",
    "    y_pred = mnb.predict(X_test)\n",
    "    y_prob = mnb.predict_proba(X_test)[:,1]\n",
    "    model.append('multinomial naive-bayes')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[41]:\n",
    "    \n",
    "    \n",
    "    print('Linear Support Vector Machine')\n",
    "    svm = LinearSVC(dual=False).fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    svm2 = LinearSVC()\n",
    "    clf = CalibratedClassifierCV(svm2) \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)[:,1]\n",
    "    model.append('linear svm')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[42]:\n",
    "    \n",
    "    \n",
    "    print('KNN')\n",
    "    knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_prob = knn.predict_proba(X_test)[:,1]\n",
    "    model.append('knn')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[45]:\n",
    "    \n",
    "    \n",
    "    print('Linear SVM with SGD training.')\n",
    "    sgd = SGDClassifier().fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_test)\n",
    "    model.append('sgd')\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm2 = SGDClassifier(loss='hinge')\n",
    "    clf = CalibratedClassifierCV(svm2) \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    \n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[43]:\n",
    "    \n",
    "    \n",
    "    print('Random Forest')\n",
    "    rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)[:,1]\n",
    "    model.append('random forest')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    \n",
    "    \n",
    "    # In[44]:\n",
    "    \n",
    "    \n",
    "    print('Gradient Boosting')\n",
    "    gb = GradientBoostingClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    y_prob = gb.predict_proba(X_test)[:,1]\n",
    "    model.append('gradient boosting')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)    \n",
    "    \n",
    "    # In[46]:\n",
    "    \n",
    "    \n",
    "    print('Multilayer perceptron')\n",
    "    mlp = MLPClassifier(max_iter = 6, verbose=True, early_stopping= True).fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    y_prob = mlp.predict_proba(X_test)[:,1]\n",
    "    model.append('mlp')\n",
    "    acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc = getTestMetrics(y_test, y_pred, y_prob, full_metrics = True, print_charts = False)\n",
    "    accuracy_score_list.append(acc)\n",
    "    precision_score_list.append(precision)\n",
    "    precision_score_neg_list.append(precision_neg)\n",
    "    recall_score_list.append(recall)\n",
    "    recall_score_neg_list.append(recall_neg)\n",
    "    f1_score_list.append(f1)\n",
    "    f1_score_neg_list.append(f1_neg)\n",
    "    auc_score_list.append(roc_auc)\n",
    "    end_time = time.time()\n",
    "    ellapsed_time = end_time - start_time\n",
    "    print('ellapsed time (min):', ellapsed_time/60)    \n",
    "    \n",
    "    df_metrics = pd.DataFrame({'model':model,                                 \n",
    "                                     'vocab':[vocab_size]*len(model),\n",
    "                                     'auc score': auc_score_list,\n",
    "                                     'accuracy':accuracy_score_list,\n",
    "                                     'precision 1': precision_score_list,\n",
    "                                     'recall 1': recall_score_list,\n",
    "                                     'f1 score 1': f1_score_list,\n",
    "                                     'precision 0': precision_score_neg_list,\n",
    "                                     'recall 0': recall_score_neg_list,                                 \n",
    "                                     'f1 score 0': f1_score_neg_list\n",
    "                                     })\n",
    "    \n",
    "    df_metrics['precision avg'] = (df_metrics['precision 1'] + df_metrics['precision 0'])/2\n",
    "    df_metrics['recall avg'] = (df_metrics['recall 1'] + df_metrics['recall 0'])/2\n",
    "    df_metrics['f1 avg'] = (df_metrics['f1 score 1'] + df_metrics['f1 score 0'])/2\n",
    "    df_metrics.set_index('model', inplace=True)\n",
    "\n",
    "    filepath = '../results/' + experiment + '.csv'\n",
    "    print(filepath)\n",
    "    df_metrics.to_csv(filepath) \n",
    "    \n",
    "#%% update files\n",
    "#    df_update = pd.read_csv(filepath)\n",
    "#    df_update.set_index('model', inplace=True)\n",
    "#    df_update.update(df_metrics)\n",
    "#    df_update = df_update.reset_index()\n",
    "#    df_update.to_csv(filepath, index = False)    \n",
    "    \n",
    "    \n",
    "    # In[35]:\n",
    "    \n",
    "    \n",
    "    #df_metrics.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_statistics = pd.read_csv('../results/ml-tfidf-unibitri_gram-random_oversampling.csv')\n",
    "\n",
    "df_model_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b57acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
